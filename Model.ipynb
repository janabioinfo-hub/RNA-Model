{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DwI1ubTjg4PlhZTWVj9sfgXFozTf-ztX",
      "authorship_tag": "ABX9TyNPnB8tzQz6/npIIaPq2yOh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janabioinfo-hub/RNA-Model/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAdgUAjvh2YF"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RNA-seq XGBoost Classification Pipeline with Job ID folders and File Upload\n",
        "# =============================================================================\n",
        "\n",
        "# ======= Setup & Imports =======\n",
        "!pip install xgboost scikit-learn matplotlib seaborn imbalanced-learn\n",
        "\n",
        "import os, uuid\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from google.colab import drive, files\n",
        "from IPython.display import display, FileLink\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ======= Mount Google Drive =======\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# ======= Dynamic Job ID & Output Folder Creation =======\n",
        "BASE_DRIVE_PATH = \"/content/drive/MyDrive/RNA_Seq_Jobs\"\n",
        "job_id = str(uuid.uuid4())[:8]\n",
        "job_folder = os.path.join(BASE_DRIVE_PATH, job_id)\n",
        "os.makedirs(job_folder, exist_ok=True)\n",
        "print(f\"Job ID: {job_id}\")\n",
        "print(f\"Outputs will be saved in: {job_folder}\")\n",
        "\n",
        "# ======= File Upload for Test Counts =======\n",
        "print(\"Please drag and drop your test counts CSV (normalized_vst_test.csv) below.\")\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    dest = os.path.join(job_folder, fn)\n",
        "    os.rename(fn, dest)\n",
        "    test_counts_path = dest\n",
        "    print(f\"Test counts file uploaded to {dest}\")\n",
        "\n",
        "# ======= Manually Set Paths for Required Files (Edit if needed) =======\n",
        "counts_path = \"/content/drive/MyDrive/Data/normalized_vst_train.csv\"\n",
        "coldata_path = \"/content/drive/MyDrive/Data/Column_Data.csv\"\n",
        "genes_list_path = \"/content/drive/MyDrive/Data/ensembl_to_gene_names.csv\"\n",
        "\n",
        "# Output paths (in job folder)\n",
        "predictions_csv = os.path.join(job_folder, \"predicted_phases.csv\")\n",
        "pca_plot_pdf = os.path.join(job_folder, \"pca_analysis.pdf\")\n",
        "individual_pca_pdf = os.path.join(job_folder, \"individual_test_pca_plots.pdf\")\n",
        "summary_plot_pdf = os.path.join(job_folder, \"test_samples_summary_pca.pdf\")\n",
        "\n",
        "# ======= Data Loading =======\n",
        "counts = pd.read_csv(counts_path, index_col=0, sep=',')\n",
        "coldata = pd.read_csv(coldata_path, header=None, sep=',')\n",
        "coldata.columns = ['sample', 'phase']\n",
        "coldata['sample'] = coldata['sample'].astype(str).str.strip()\n",
        "genes = pd.read_csv(genes_list_path, header=None).iloc[:, 0].tolist()\n",
        "print(f\"Loaded counts: {counts.shape}, samples: {counts.columns.size}, genes: {counts.index.size}\")\n",
        "\n",
        "# ======= Data Preparation =======\n",
        "counts_filtered = counts.loc[counts.index.isin(genes)]\n",
        "X_full = counts_filtered.transpose()\n",
        "X_full.index = X_full.index.astype(str).str.strip()\n",
        "data = X_full.merge(coldata, left_index=True, right_on='sample')\n",
        "print(data['phase'].value_counts())\n",
        "\n",
        "# ======= Oversampling =======\n",
        "def oversample_to_majority(df, class_col):\n",
        "    class_counts = df[class_col].value_counts()\n",
        "    max_count = class_counts.max()\n",
        "    features = df.drop(columns=['sample', class_col])\n",
        "    labels = df[class_col]\n",
        "    over_sampler = RandomOverSampler(sampling_strategy='not majority', random_state=42)\n",
        "    X_res, y_res = over_sampler.fit_resample(features, labels)\n",
        "    balanced_df = pd.DataFrame(X_res, columns=features.columns)\n",
        "    balanced_df[class_col] = y_res\n",
        "    return balanced_df\n",
        "\n",
        "balanced_data = oversample_to_majority(data, 'phase')\n",
        "print(balanced_data['phase'].value_counts())\n",
        "X_balanced = balanced_data.drop(columns=['phase'])\n",
        "y_balanced = balanced_data['phase']\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y_balanced)\n",
        "print({phase: idx for idx, phase in enumerate(label_encoder.classes_)})\n",
        "\n",
        "# ======= Train-Validation Split =======\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_balanced, y_encoded, test_size=0.25, stratify=y_encoded, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# ======= Model Training =======\n",
        "model = xgb.XGBClassifier(\n",
        "    eval_metric='mlogloss', random_state=42, n_estimators=100, max_depth=4,\n",
        "    learning_rate=0.1, reg_alpha=0.1, reg_lambda=0.1)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_val = model.predict(X_val_scaled)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(classification_report(y_val, y_pred_val, target_names=label_encoder.classes_))\n",
        "\n",
        "# ======= Load Test Data & Prediction =======\n",
        "test_counts = pd.read_csv(test_counts_path, index_col=0)\n",
        "test_counts_filtered = test_counts.loc[test_counts.index.isin(genes)]\n",
        "X_test = test_counts_filtered.transpose()\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "test_predictions_encoded = model.predict(X_test_scaled)\n",
        "test_predictions = label_encoder.inverse_transform(test_predictions_encoded)\n",
        "test_probabilities = model.predict_proba(X_test_scaled)\n",
        "print(f\"Test samples: {X_test.index.size}, Genes: {X_test.columns.size}\")\n",
        "\n",
        "# ======= Save Predictions =======\n",
        "predictions_df = pd.DataFrame({\n",
        "    'sample': X_test.index,\n",
        "    'predicted_phase': test_predictions\n",
        "})\n",
        "for i, phase in enumerate(label_encoder.classes_):\n",
        "    predictions_df[f'prob_{phase}'] = test_probabilities[:, i]\n",
        "predictions_df.to_csv(predictions_csv, index=False)\n",
        "print(f\"Predictions saved to: {predictions_csv}\")\n",
        "print(pd.Series(test_predictions).value_counts())\n",
        "\n",
        "# ======= PCA Analysis & Visualization =======\n",
        "combined_data = np.vstack([X_train_scaled, X_val_scaled, X_test_scaled])\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X_train_scaled)\n",
        "train_pca = pca.transform(X_train_scaled)\n",
        "val_pca = pca.transform(X_val_scaled)\n",
        "test_pca = pca.transform(X_test_scaled)\n",
        "num_train = X_train_scaled.shape[0]\n",
        "num_val = X_val_scaled.shape[0]\n",
        "num_test = X_test_scaled.shape[0]\n",
        "plot_df = pd.DataFrame(\n",
        "    np.vstack([train_pca, val_pca, test_pca]), columns=['PC1', 'PC2'])\n",
        "plot_df['dataset'] = (\n",
        "    ['Training'] * num_train + ['Validation'] * num_val + ['Test'] * num_test)\n",
        "plot_df['phase'] = np.concatenate([\n",
        "    label_encoder.inverse_transform(y_train),\n",
        "    label_encoder.inverse_transform(y_val),\n",
        "    test_predictions\n",
        "])\n",
        "\n",
        "# === Individual PCA Plots for Each Test Sample ===\n",
        "with PdfPages(individual_pca_pdf) as pdf:\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    train_phases = label_encoder.inverse_transform(y_train)\n",
        "    colors = sns.color_palette(\"Set1\", n_colors=len(label_encoder.classes_))\n",
        "    phase_colors = {phase: colors[i] for i, phase in enumerate(label_encoder.classes_)}\n",
        "    for phase in label_encoder.classes_:\n",
        "        phase_mask = train_phases == phase\n",
        "        plt.scatter(train_pca[phase_mask, 0], train_pca[phase_mask, 1], c=[phase_colors[phase]], s=60, alpha=0.7, label=f'{phase} (Train)')\n",
        "    plt.title(\"Training Data PCA Space (Reference)\")\n",
        "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    pdf.savefig()\n",
        "    plt.close()\n",
        "    for i, sample_name in enumerate(X_test.index):\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        for phase in label_encoder.classes_:\n",
        "            phase_mask = train_phases == phase\n",
        "            plt.scatter(train_pca[phase_mask, 0], train_pca[phase_mask, 1], c=[phase_colors[phase]], s=40, alpha=0.3, label=f'{phase} (Train)')\n",
        "        test_point = test_pca[i]\n",
        "        predicted_phase = test_predictions[i]\n",
        "        plt.scatter(test_point[0], test_point[1], c='red', s=200, marker='*', edgecolors='black', linewidth=2, label=f'{sample_name}\\n(Predicted: {predicted_phase})')\n",
        "        prob_text = \"Prediction Probabilities:\\n\"\n",
        "        for j, phase in enumerate(label_encoder.classes_):\n",
        "            prob_text += f\"{phase}: {test_probabilities[i,j]:.3f}\\n\"\n",
        "        plt.text(0.02, 0.98, prob_text, transform=plt.gca().transAxes, fontsize=9, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "        plt.title(f\"Test Sample: {sample_name}\\nPredicted Phase: {predicted_phase}\")\n",
        "        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        pdf.savefig()\n",
        "        plt.close()\n",
        "print(f\"Individual PCA plots saved to: {individual_pca_pdf}\")\n",
        "\n",
        "# === Summary PCA Plot for All Test Samples ===\n",
        "plt.figure(figsize=(12, 10))\n",
        "for phase in label_encoder.classes_:\n",
        "    phase_mask = train_phases == phase\n",
        "    plt.scatter(train_pca[phase_mask, 0], train_pca[phase_mask, 1], c=[phase_colors[phase]], s=40, alpha=0.3, label=f'{phase} (Train)')\n",
        "for i, sample_name in enumerate(X_test.index):\n",
        "    test_point = test_pca[i]\n",
        "    predicted_phase = test_predictions[i]\n",
        "    plt.scatter(test_point[0], test_point[1], c=[phase_colors[predicted_phase]], s=150, marker='D', edgecolors='black', linewidth=1, alpha=0.9)\n",
        "    plt.annotate(sample_name, (test_point[0], test_point[1]), xytext=(5,5), textcoords='offset points', fontsize=8, alpha=0.8)\n",
        "plt.title(\"All Test Samples Projected on Training PCA Space\")\n",
        "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "plt.legend(title=\"Training Phases\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(summary_plot_pdf, format='pdf', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n",
        "print(f\"Summary PCA plot saved to: {summary_plot_pdf}\")\n",
        "\n",
        "# === Display Downloadable Links to Outputs ===\n",
        "print(\"Download Results:\")\n",
        "display(FileLink(predictions_csv))\n",
        "display(FileLink(individual_pca_pdf))\n",
        "display(FileLink(summary_plot_pdf))\n",
        "\n",
        "# ==== Final Job Summary ====\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Job ID: {job_id}\")\n",
        "print(f\"Model validation accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Test samples predicted: {len(test_predictions)}\")\n",
        "print(\"Outputs:\")\n",
        "print(f\"- Predictions CSV: {predictions_csv}\")\n",
        "print(f\"- Individual PCA PDF: {individual_pca_pdf}\")\n",
        "print(f\"- Summary PCA PDF: {summary_plot_pdf}\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ]
}